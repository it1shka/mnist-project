{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "tf = ToTensor()\n",
    "train_dataset = MNIST(root='./data', train=True, transform=tf, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvolutionNetwork(nn.Module):\n",
    "  '''Network with convolutional layers'''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.convolution_stack = nn.Sequential(\n",
    "      # convolutional part\n",
    "      nn.Conv2d(1, 10, kernel_size=3),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(10, 20, kernel_size=3),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.dense_stack = nn.Sequential(\n",
    "      # dense part\n",
    "      nn.Linear(2880, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.1),\n",
    "      nn.Linear(128, 10),\n",
    "      nn.Softmax(dim=1)\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.convolution_stack(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_stack(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  '''Network created with some help'''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.convolution_stack = nn.Sequential(\n",
    "      nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.Dropout2d(0.25)\n",
    "    )\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.dense_stack = nn.Sequential (\n",
    "      nn.Linear(64 * 14 * 14, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.Linear(128, 10),\n",
    "      nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.convolution_stack(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_stack(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "  'cuda' if torch.cuda.is_available() else\n",
    "  'mps' if torch.backends.mps.is_available() else \n",
    "  'cpu'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tikhon/Documents/other-projects/mnist-dataset/.venv/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:218.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.1045, 0.0978, 0.1035, 0.0969, 0.0991, 0.0927, 0.0930, 0.1103,\n",
       "         0.1123],\n",
       "        [0.0955, 0.1037, 0.1006, 0.1012, 0.0926, 0.0945, 0.1012, 0.0986, 0.1106,\n",
       "         0.1015],\n",
       "        [0.0957, 0.1067, 0.0971, 0.0982, 0.1012, 0.1013, 0.0926, 0.0935, 0.1128,\n",
       "         0.1009],\n",
       "        [0.0948, 0.1092, 0.1023, 0.1008, 0.0872, 0.0906, 0.0948, 0.1025, 0.1122,\n",
       "         0.1056],\n",
       "        [0.0943, 0.1024, 0.0905, 0.1041, 0.0998, 0.0966, 0.0971, 0.0963, 0.1173,\n",
       "         0.1014],\n",
       "        [0.1003, 0.1042, 0.0975, 0.0996, 0.0957, 0.0952, 0.0958, 0.0970, 0.1065,\n",
       "         0.1081],\n",
       "        [0.0951, 0.1050, 0.0958, 0.1053, 0.0970, 0.0957, 0.0925, 0.1003, 0.1103,\n",
       "         0.1030],\n",
       "        [0.0954, 0.1096, 0.0980, 0.1014, 0.0955, 0.1001, 0.0971, 0.0981, 0.1071,\n",
       "         0.0976],\n",
       "        [0.0912, 0.1052, 0.1000, 0.1046, 0.0958, 0.0983, 0.0934, 0.0970, 0.1082,\n",
       "         0.1062],\n",
       "        [0.0944, 0.0981, 0.0926, 0.1101, 0.1006, 0.0933, 0.0909, 0.0965, 0.1202,\n",
       "         0.1033],\n",
       "        [0.0916, 0.1093, 0.1000, 0.1018, 0.1017, 0.0965, 0.0960, 0.0958, 0.1026,\n",
       "         0.1049],\n",
       "        [0.0965, 0.1013, 0.0949, 0.1043, 0.0918, 0.0961, 0.0966, 0.0955, 0.1146,\n",
       "         0.1084],\n",
       "        [0.0925, 0.1053, 0.0976, 0.1061, 0.0976, 0.0937, 0.0945, 0.0995, 0.1096,\n",
       "         0.1036],\n",
       "        [0.0934, 0.1023, 0.0908, 0.1065, 0.1015, 0.0907, 0.0966, 0.0973, 0.1142,\n",
       "         0.1067],\n",
       "        [0.0987, 0.1027, 0.0962, 0.1045, 0.0920, 0.0952, 0.0999, 0.0958, 0.1100,\n",
       "         0.1050],\n",
       "        [0.0979, 0.1046, 0.0927, 0.1060, 0.0896, 0.0967, 0.0949, 0.1020, 0.1114,\n",
       "         0.1042],\n",
       "        [0.0984, 0.1022, 0.0963, 0.1040, 0.0945, 0.0948, 0.0967, 0.1010, 0.1086,\n",
       "         0.1035],\n",
       "        [0.0963, 0.1055, 0.0938, 0.1075, 0.0936, 0.0965, 0.0969, 0.1037, 0.1063,\n",
       "         0.0999],\n",
       "        [0.1004, 0.1074, 0.0941, 0.1051, 0.0954, 0.0989, 0.0933, 0.0997, 0.1082,\n",
       "         0.0976],\n",
       "        [0.0925, 0.1032, 0.1006, 0.0977, 0.0909, 0.1020, 0.0868, 0.1056, 0.1198,\n",
       "         0.1008],\n",
       "        [0.0939, 0.1127, 0.0949, 0.1075, 0.0990, 0.0922, 0.0938, 0.0963, 0.1086,\n",
       "         0.1012],\n",
       "        [0.0969, 0.1122, 0.0934, 0.1027, 0.0914, 0.1008, 0.0947, 0.0952, 0.1112,\n",
       "         0.1016],\n",
       "        [0.0961, 0.1015, 0.1013, 0.1035, 0.0987, 0.0992, 0.0968, 0.0955, 0.1078,\n",
       "         0.0996],\n",
       "        [0.0951, 0.0973, 0.0960, 0.1023, 0.0971, 0.1008, 0.0944, 0.0917, 0.1168,\n",
       "         0.1086],\n",
       "        [0.0956, 0.1064, 0.0916, 0.1032, 0.0968, 0.0932, 0.0923, 0.0984, 0.1148,\n",
       "         0.1076],\n",
       "        [0.0984, 0.0973, 0.0951, 0.1018, 0.0948, 0.1011, 0.0949, 0.1006, 0.1130,\n",
       "         0.1028],\n",
       "        [0.0994, 0.1060, 0.0999, 0.1035, 0.0922, 0.0998, 0.0953, 0.0941, 0.1093,\n",
       "         0.1005],\n",
       "        [0.0947, 0.1055, 0.1025, 0.1033, 0.0970, 0.0950, 0.0950, 0.1024, 0.1056,\n",
       "         0.0990],\n",
       "        [0.0966, 0.1040, 0.0971, 0.1029, 0.0955, 0.1010, 0.0936, 0.0935, 0.1104,\n",
       "         0.1055],\n",
       "        [0.0922, 0.1085, 0.0971, 0.1009, 0.0949, 0.0961, 0.0948, 0.0920, 0.1159,\n",
       "         0.1076],\n",
       "        [0.0937, 0.1056, 0.0994, 0.1002, 0.0936, 0.0975, 0.0931, 0.0915, 0.1191,\n",
       "         0.1063],\n",
       "        [0.0969, 0.1055, 0.0943, 0.1063, 0.0909, 0.0957, 0.0954, 0.0962, 0.1148,\n",
       "         0.1040],\n",
       "        [0.0996, 0.1052, 0.0914, 0.1034, 0.0985, 0.0971, 0.0993, 0.0971, 0.1074,\n",
       "         0.1010],\n",
       "        [0.1019, 0.1113, 0.0926, 0.1103, 0.1011, 0.0915, 0.0960, 0.0904, 0.1096,\n",
       "         0.0953],\n",
       "        [0.0980, 0.1068, 0.0925, 0.1091, 0.0978, 0.0985, 0.1005, 0.0927, 0.1087,\n",
       "         0.0953],\n",
       "        [0.0932, 0.1070, 0.0953, 0.1024, 0.0988, 0.0981, 0.0957, 0.0955, 0.1161,\n",
       "         0.0979],\n",
       "        [0.0990, 0.1065, 0.0973, 0.1030, 0.0928, 0.0960, 0.0948, 0.0978, 0.1100,\n",
       "         0.1027],\n",
       "        [0.0939, 0.1046, 0.0973, 0.0945, 0.0948, 0.1055, 0.0985, 0.0995, 0.1108,\n",
       "         0.1006],\n",
       "        [0.1006, 0.1084, 0.0959, 0.0995, 0.0950, 0.0955, 0.1034, 0.0958, 0.1106,\n",
       "         0.0953],\n",
       "        [0.1040, 0.1025, 0.0923, 0.1069, 0.0965, 0.0930, 0.0953, 0.0885, 0.1130,\n",
       "         0.1082],\n",
       "        [0.0976, 0.1016, 0.0945, 0.1076, 0.0935, 0.0973, 0.0967, 0.0992, 0.1121,\n",
       "         0.0999],\n",
       "        [0.0963, 0.1085, 0.0970, 0.1077, 0.0959, 0.0923, 0.0939, 0.0859, 0.1192,\n",
       "         0.1034],\n",
       "        [0.0981, 0.1049, 0.0997, 0.1020, 0.0967, 0.0908, 0.1038, 0.0970, 0.1078,\n",
       "         0.0992],\n",
       "        [0.0942, 0.1122, 0.1067, 0.0967, 0.0883, 0.1030, 0.0925, 0.0901, 0.1125,\n",
       "         0.1039],\n",
       "        [0.0924, 0.1161, 0.0950, 0.0924, 0.0995, 0.1011, 0.0914, 0.0956, 0.1116,\n",
       "         0.1049],\n",
       "        [0.0962, 0.1133, 0.0965, 0.1041, 0.0910, 0.0952, 0.0919, 0.0910, 0.1106,\n",
       "         0.1102],\n",
       "        [0.1005, 0.1044, 0.0922, 0.1089, 0.0913, 0.0972, 0.0989, 0.0954, 0.1098,\n",
       "         0.1014],\n",
       "        [0.0995, 0.1063, 0.0982, 0.0985, 0.0985, 0.1024, 0.0933, 0.0908, 0.1088,\n",
       "         0.1037],\n",
       "        [0.0957, 0.1070, 0.0993, 0.1031, 0.0952, 0.0958, 0.0947, 0.0973, 0.1094,\n",
       "         0.1025],\n",
       "        [0.0989, 0.1026, 0.0941, 0.0994, 0.0982, 0.0962, 0.0960, 0.1016, 0.1162,\n",
       "         0.0968],\n",
       "        [0.0946, 0.1037, 0.0998, 0.1133, 0.0953, 0.0979, 0.0938, 0.0978, 0.1096,\n",
       "         0.0942],\n",
       "        [0.0958, 0.0980, 0.0956, 0.1015, 0.0975, 0.0966, 0.0947, 0.1005, 0.1150,\n",
       "         0.1048],\n",
       "        [0.0974, 0.1047, 0.0909, 0.1074, 0.0950, 0.1011, 0.0990, 0.0939, 0.1062,\n",
       "         0.1045],\n",
       "        [0.0975, 0.1079, 0.1000, 0.1035, 0.0910, 0.1018, 0.0900, 0.0944, 0.1114,\n",
       "         0.1026],\n",
       "        [0.0977, 0.1030, 0.0972, 0.0998, 0.0987, 0.0966, 0.0968, 0.0966, 0.1084,\n",
       "         0.1051],\n",
       "        [0.0958, 0.1037, 0.0908, 0.1129, 0.0994, 0.0951, 0.0966, 0.0954, 0.1119,\n",
       "         0.0985],\n",
       "        [0.0985, 0.1065, 0.0890, 0.1019, 0.0896, 0.1013, 0.0952, 0.1054, 0.1090,\n",
       "         0.1037],\n",
       "        [0.0991, 0.1033, 0.0936, 0.1067, 0.0967, 0.0951, 0.0944, 0.1040, 0.1063,\n",
       "         0.1009],\n",
       "        [0.0972, 0.1093, 0.0963, 0.1096, 0.0938, 0.0954, 0.0985, 0.0976, 0.1035,\n",
       "         0.0987],\n",
       "        [0.0917, 0.1079, 0.0922, 0.1118, 0.0894, 0.0990, 0.0996, 0.0950, 0.1110,\n",
       "         0.1024],\n",
       "        [0.0949, 0.1006, 0.0962, 0.1112, 0.0939, 0.0955, 0.0951, 0.0993, 0.1144,\n",
       "         0.0989],\n",
       "        [0.0925, 0.1058, 0.0940, 0.1065, 0.1017, 0.0979, 0.0947, 0.0922, 0.1108,\n",
       "         0.1040],\n",
       "        [0.0984, 0.1021, 0.1005, 0.1078, 0.0943, 0.0918, 0.0933, 0.0988, 0.1118,\n",
       "         0.1012],\n",
       "        [0.0992, 0.1087, 0.0959, 0.1074, 0.0952, 0.0928, 0.0986, 0.0962, 0.1051,\n",
       "         0.1009]], device='mps:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first batch\n",
    "images, _ = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "prediction = model(images)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last loss = 1.4687466621398926\n",
      "Epoch 1: last loss = 1.463024616241455\n",
      "Epoch 2: last loss = 1.4873768091201782\n",
      "Epoch 3: last loss = 1.5252296924591064\n",
      "Epoch 4: last loss = 1.4612271785736084\n",
      "Epoch 5: last loss = 1.515791893005371\n",
      "Epoch 6: last loss = 1.500974416732788\n",
      "Epoch 7: last loss = 1.467198371887207\n",
      "Epoch 8: last loss = 1.4959962368011475\n",
      "Epoch 9: last loss = 1.4614734649658203\n",
      "Epoch 10: last loss = 1.4631645679473877\n",
      "Epoch 11: last loss = 1.4918979406356812\n",
      "Epoch 12: last loss = 1.4612102508544922\n",
      "Epoch 13: last loss = 1.4611504077911377\n",
      "Epoch 14: last loss = 1.4935476779937744\n",
      "Epoch 15: last loss = 1.4611501693725586\n",
      "Epoch 16: last loss = 1.4611501693725586\n",
      "Epoch 17: last loss = 1.461150050163269\n",
      "Epoch 18: last loss = 1.4935702085494995\n",
      "Epoch 19: last loss = 1.4611506462097168\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for current_epoch in range(epochs):\n",
    "  for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(images)\n",
    "    loss = loss_function(predictions, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(f'Epoch {current_epoch}: last loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.95%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    # print(images.shape)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    predictions = model(images)\n",
    "    # print(predictions.shape)\n",
    "    _, predicted = torch.max(predictions.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "postfix = str(round(accuracy * 1e4))\n",
    "path = f'./models/model_{postfix}.pth'\n",
    "torch.save(model, path)\n",
    "state = model.state_dict()\n",
    "torch.save(state, f'{path}.state')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
